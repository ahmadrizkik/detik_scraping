{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9080702-d22c-40ab-b78c-a2f6cd545e6f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2144b812-8dc6-4106-a1b8-cbe5b41e4636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173a677a-21f6-49ec-94a8-ea2887829bdd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get Article Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875ae26a-8aae-4bcd-89a5-799aeaa27682",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "keyword = input(\"Looking for? \")\n",
    "\n",
    "number = 0\n",
    "\n",
    "driver = webdriver.Edge()\n",
    "driver.get(\"https://www.detik.com\")\n",
    "\n",
    "search_box = driver.find_element(By.NAME, \"query\")\n",
    "search_box.clear()\n",
    "search_box.send_keys(keyword)\n",
    "search_box.send_keys(Keys.ENTER)\n",
    "\n",
    "try:\n",
    "    all_news = driver.find_elements(By.CLASS_NAME, \"title\")\n",
    "    for news in all_news:\n",
    "        number += 1\n",
    "        print(f\"{number}. {news.text}\")\n",
    "    driver.quit()\n",
    "except:\n",
    "    print(\"error\")\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b0bdd9-6ace-46fa-ba2a-954b3de858a6",
   "metadata": {},
   "source": [
    "## Get First Article Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94082632-2a12-440d-ac5b-0477661d38f9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "keyword = input(\"Looking for? \")\n",
    "\n",
    "driver = webdriver.Edge()\n",
    "driver.get(\"https://www.detik.com\")\n",
    "\n",
    "search_box = driver.find_element(By.NAME, \"query\")\n",
    "search_box.clear()\n",
    "search_box.send_keys(keyword)\n",
    "search_box.send_keys(Keys.ENTER)\n",
    "\n",
    "try:\n",
    "    news_title = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CLASS_NAME, \"title\")))\n",
    "    news_title.click()\n",
    "    \n",
    "    main_body = driver.find_element(By.CLASS_NAME, \"detail__body-text.itp_bodycontent\")\n",
    "    print(main_body.text)\n",
    "    \n",
    "    time.sleep(3)\n",
    "    \n",
    "    driver.quit()\n",
    "except:\n",
    "    print(\"error\")\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf43de8-b77c-42ee-9a28-53f949edec55",
   "metadata": {},
   "source": [
    "## Try to Fix Class Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e945bbf7-2b86-45be-9472-ec634bbc8cca",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Edge()\n",
    "driver.get(\"https://www.detik.com/sulsel/berita/d-6065524/pemudik-dari-belopa-tabrak-baruga-rumah-warga-di-barru-gegara-sopir-mengantuk\")\n",
    "\n",
    "try:\n",
    "    main_body = driver.find_element(By.CLASS_NAME, \"detail__body-text.itp_bodycontent\")\n",
    "    print(main_body.text)\n",
    "    driver.quit()\n",
    "except:\n",
    "    print(\"Eror\")\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31333ae-dc3e-41ef-b623-9b5d23431d04",
   "metadata": {},
   "source": [
    "## Get Article Title-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010587dd-1e82-4927-889e-0afc5954c9e4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "keyword = input(\"Looking for? \")\n",
    "\n",
    "driver = webdriver.Edge()\n",
    "driver.get(\"https://www.detik.com\")\n",
    "\n",
    "search_box = driver.find_element(By.NAME, \"query\")\n",
    "search_box.clear()\n",
    "search_box.send_keys(keyword)\n",
    "search_box.send_keys(Keys.ENTER)\n",
    "\n",
    "news_title = driver.find_elements(By.TAG_NAME, \"article\")\n",
    "\n",
    "number = 0\n",
    "for news in news_title:\n",
    "    news = news.find_element(By.CLASS_NAME, \"title\")\n",
    "\n",
    "    time.sleep(3)\n",
    "    number += 1\n",
    "    print(f\"Berita ke: {number}\")\n",
    "    print(news.text)\n",
    "    \n",
    "    time.sleep(2)\n",
    "    \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed087b4-2beb-4397-91c1-56fede6b9f86",
   "metadata": {},
   "source": [
    "## Tag Name \"p\" Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e6968e-852c-4cc5-973b-1007e840a9b0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Edge(service=service, options=options)\n",
    "driver.get(\"https://www.detik.com/sulsel/berita/d-6065524/pemudik-dari-belopa-tabrak-baruga-rumah-warga-di-barru-gegara-sopir-mengantuk\")\n",
    "\n",
    "try:\n",
    "    main_body = driver.find_element(By.CLASS_NAME, \"detail__body-text.itp_bodycontent\")\n",
    "    bodies = main_body.find_elements(By.TAG_NAME, \"p\")\n",
    "    for body in bodies:\n",
    "        print(body.text)\n",
    "    driver.quit()\n",
    "except:\n",
    "    print(\"Eror\")\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84978f20-0274-4ebe-8d39-e90659f7f85c",
   "metadata": {},
   "source": [
    "## Combine with BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1068e310-582b-495d-ad9a-ad49b0532d0a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Edge()\n",
    "driver.get(\"https://www.detik.com/sulsel/berita/d-6065524/pemudik-dari-belopa-tabrak-baruga-rumah-warga-di-barru-gegara-sopir-mengantuk\")\n",
    "\n",
    "# beautiful soup package\n",
    "html = driver.execute_script(\"return document.getElementsByTagName('html')[0].innerHTML\")\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "news = soup.find('div', class_=\"detail__body-text itp_bodycontent\")\n",
    "print(news.get_text())\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901f6414-66b5-4660-bc0e-e7538da5a881",
   "metadata": {},
   "source": [
    "## Going to Next Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296bd438-3675-4071-9468-74b326a18dda",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "keyword = input(\"Looking for? \")\n",
    "\n",
    "driver = webdriver.Edge()\n",
    "driver.get(\"https://www.detik.com\")\n",
    "\n",
    "search_box = driver.find_element(By.NAME, \"query\")\n",
    "search_box.clear()\n",
    "search_box.send_keys(keyword)\n",
    "search_box.send_keys(Keys.ENTER)\n",
    "\n",
    "print(\"Halaman 1\")\n",
    "\n",
    "for page in range(2,11):\n",
    "    print(f\"Halaman {page}\")\n",
    "    next_page = driver.find_element(By.LINK_TEXT, str(page))\n",
    "    next_page.click()\n",
    "    time.sleep(2)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f117e7-b425-4b27-afb6-66ee8f11d672",
   "metadata": {},
   "source": [
    "## Get News in New Browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e51e463-f0a8-46ac-b2b6-532c12c74db4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Edge()\n",
    "driver2 = webdriver.Edge()\n",
    "\n",
    "driver.get(\"https://www.detik.com/search/searchall?query=mudik+2022&siteid=2\")\n",
    "\n",
    "list_berita = driver.find_element(By.CLASS_NAME, \"list.media_rows.list-berita\")\n",
    "article = list_berita.find_element(By.TAG_NAME, \"a\")\n",
    "url = article.get_attribute(\"href\")\n",
    "\n",
    "driver2.get(url)\n",
    "\n",
    "# Get title news\n",
    "try:\n",
    "    main_title = driver2.find_element(By.CLASS_NAME, \"detail__title\")\n",
    "    print(f\"Judul Berita\\n{main_title.text}\\n\")\n",
    "    judul_berita = main_title.text\n",
    "except:\n",
    "    try:\n",
    "        main_title = driver2.find_element(By.TAG_NAME, \"h1\")\n",
    "        print(f\"Judul Berita\\n{main_title.text}\\n\")\n",
    "        judul_berita = main_title.text\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Get body news\n",
    "try:\n",
    "    main_body = driver2.find_element(By.CLASS_NAME, \"detail__body-text.itp_bodycontent\")\n",
    "    print(f\"Isi Berita\\n{main_body.text}\")\n",
    "    isi_berita = main_body.text\n",
    "except:\n",
    "    try:\n",
    "        main_body = driver2.find_element(By.ID, \"detikdetailtext\")\n",
    "        print(f\"Isi Berita\\n{main_body.text}\")\n",
    "        isi_berita = main_body.text\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "driver2.quit()\n",
    "    \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7765dbca-8832-463e-a5b3-9e38cc85009a",
   "metadata": {},
   "source": [
    "## Get news in New Tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0ae17d-33ff-4c6f-8b6b-25d4db9c15b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge()\n",
    "\n",
    "driver.get(\"https://www.detik.com/search/searchall?query=mudik+2022&siteid=2\")\n",
    "\n",
    "list_berita = driver.find_element(By.CLASS_NAME, \"list.media_rows.list-berita\")\n",
    "articles = list_berita.find_elements(By.TAG_NAME, \"a\")\n",
    "\n",
    "url = []\n",
    "for link in articles:\n",
    "    url.append(link.get_attribute(\"href\"))\n",
    "\n",
    "driver.execute_script(\"window.open('');\")\n",
    "driver.switch_to.window(driver.window_handles[1])\n",
    "\n",
    "news = []\n",
    "for index in range(5):\n",
    "    driver.get(url[index])\n",
    "    \n",
    "    # Get title news\n",
    "    try:\n",
    "        main_title = driver.find_element(By.CLASS_NAME, \"detail__title\")\n",
    "        # print(f\"Judul Berita\\n{main_title.text}\\n\")\n",
    "        main_title = main_title.text\n",
    "    except:\n",
    "        try:\n",
    "            main_title = driver.find_element(By.TAG_NAME, \"h1\")\n",
    "            # print(f\"Judul Berita\\n{main_title.text}\\n\")\n",
    "            main_title = main_title.text\n",
    "        except:\n",
    "            main_title = None\n",
    "\n",
    "    # Get body news\n",
    "    try:\n",
    "        main_body = driver.find_element(By.CLASS_NAME, \"detail__body-text.itp_bodycontent\")\n",
    "        # print(f\"Isi Berita\\n{main_body.text}\")\n",
    "        main_body = main_body.text\n",
    "    except:\n",
    "        try:\n",
    "            main_body = driver.find_element(By.ID, \"detikdetailtext\")\n",
    "            # print(f\"Isi Berita\\n{main_body.text}\")\n",
    "            main_body = main_body.text\n",
    "        except:\n",
    "            main_body = None\n",
    "    \n",
    "    news.append({\"judul\": main_title, \"isi\": main_body})\n",
    "    # driver.close()\n",
    "    time.sleep(3)\n",
    "    \n",
    "driver.quit()\n",
    "    \n",
    "df = pd.DataFrame(news)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c55de1-eae8-4fcf-b11e-22eaa908fd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"list berita.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f166636e-4264-4f43-8847-7a7967e6da0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"list berita.csv\")\n",
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073edd02-ad14-4860-87d2-9165a90fc5e1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df.isi.iloc[14])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72465986-6e81-4744-9c69-ba268c9b36e1",
   "metadata": {},
   "source": [
    "## Get Cleaner Body News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a427b2d5-827b-4c85-a1ab-a01c45d0a7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge()\n",
    "\n",
    "# keyword = \"gunung anak krakatau\"\n",
    "\n",
    "# driver.get(\"https://news.detik.com\")\n",
    "driver.get(\"https://www.detik.com/search/searchall?query=gunung+anak+krakatau&siteid=3#\")\n",
    "\n",
    "# try:\n",
    "#     search_bar = WebDriverWait(driver, 10).until(\n",
    "#     EC.presence_of_element_located((By.NAME, \"query\")))\n",
    "#     search_bar.clear()\n",
    "#     search_bar.send_keys(keyword)\n",
    "#     search_bar.send_keys(Keys.ENTER)\n",
    "# except:\n",
    "#     print(\"Error: No such search box\")\n",
    "    \n",
    "try:\n",
    "    all_link = []\n",
    "    links = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.CLASS_NAME, \"list.media_rows.list-berita\")))\n",
    "    links = links.find_elements(By.TAG_NAME, \"article\")    \n",
    "    for link in links:\n",
    "        link = link.find_element(By.TAG_NAME, \"a\")\n",
    "        all_link.append(link.get_attribute(\"href\"))\n",
    "    print(f\"link: {all_link}\")\n",
    "except:\n",
    "    print(\"Error: No such link\")\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a3bd7d-9a00-4119-8ae4-81a98e8ca3aa",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for link in all_link:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce65050b-a987-48b6-be2f-c14bb1726a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(all_link[0]).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb56db5-b61c-4601-afb1-09fe32e8c91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba91ca0-c65d-4d12-afd9-e0f382d7de3c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806c4a97-af4d-4c2d-91ae-da776362cff2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "tag = soup.find(class_=\"detail__title\")\n",
    "clean_tag = tag.get_text(strip=True)\n",
    "clean_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06778d39-0980-413e-ac5c-71f1afaa7368",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "nb = soup.find(class_=\"detail__body-text itp_bodycontent\")\n",
    "print(nb.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7794c8f-e9b9-4c07-a400-2b04efb3fb4d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "nbb = [index.get_text() for index in nb]\n",
    "nbb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dcb587-b6e1-4370-b6a0-d61f859c2936",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_fw = nb.strong.get_text()\n",
    "nb_fw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37316f65-820d-44ab-a8af-bc3c5f709857",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_list = nb.find_all(\"p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785d15a0-47da-45cf-b479-fac740a0b613",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnb_list = [body.get_text() for body in nb_list]\n",
    "nnb_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a818839-d6a1-43b5-932b-c0d13d5c1f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "del nnb_list[-5:]\n",
    "nnb_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b2f652-d5a7-4b8e-bb2b-96b7910b7bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnb_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f009a16-5c0f-49bc-8783-dab517cc5c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_body = \"\\n\".join(nnb_list)\n",
    "print(news_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d2db17-13cf-4ecd-83dc-5390bfa17fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"judul\":clean_tag, \"isi\":news_body}, index=[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dab698-d9c1-4afc-a8aa-2d7fb86c289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.judul.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcfd5ed-e660-4370-914d-03afe11bc5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isi.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9cf693-72d6-4ed2-8018-d9be35238999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"berita.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cd9e14-3220-4a39-9d48-68e9e6f9a9b0",
   "metadata": {},
   "source": [
    "## Get Cleaner News Using Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95baa4b9-0ed3-486c-b69a-0a48d775bd21",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "driver = webdriver.Edge()\n",
    "\n",
    "driver.get(\"https://sport.detik.com/raket/d-6070720/hasil-uber-cup-2022-sikat-jerman-5-0-indonesia-tembus-perempatfinal?_ga=2.78170580.1343754793.1652070475-514423723.1651498784\")\n",
    "\n",
    "try:\n",
    "    time.sleep(2)\n",
    "    news_title = driver.find_element(By.CLASS_NAME, \"detail__title\")\n",
    "    print(f\"{news_title.text}\\n\")\n",
    "except:\n",
    "    print(\"Error: No such news title element\")\n",
    "    \n",
    "try:\n",
    "    time.sleep(2)\n",
    "    content_body = driver.find_element(By.CLASS_NAME, \"detail__body-text.itp_bodycontent\")\n",
    "    head_news = content_body.find_element(By.TAG_NAME, \"strong\").text\n",
    "    raw_news = content_body.find_elements(By.TAG_NAME, \"p\")\n",
    "    body_news = [news.text for news in raw_news]\n",
    "    body_news = \"\\n\".join(body_news)\n",
    "    print(f\"{head_news}-{body_news}\")\n",
    "except:\n",
    "    print(\"Error: No such news body element\")\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77b5715-8d0b-474e-a100-8fc7f13dff2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge()\n",
    "\n",
    "driver.get(\"https://news.detik.com/berita/d-6056177/badan-geologi-aktivitas-gunung-anak-krakatau-sudah-mereda?_ga=2.9512309.1343754793.1652070475-514423723.1651498784\")\n",
    "\n",
    "# try:\n",
    "time.sleep(1)\n",
    "content_body = driver.find_element(By.CLASS_NAME, \"detail__body-text.itp_bodycontent\")\n",
    "head_news = content_body.find_element(By.TAG_NAME, \"strong\").text\n",
    "raw_news = content_body.find_elements(By.TAG_NAME, \"p\")\n",
    "body_news = [news.text for news in raw_news]\n",
    "# body_news = \"\\n\".join(body_news)\n",
    "print(body_news)\n",
    "# except:\n",
    "#     print(\"Error: No such news body element\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a523e1-6a17-4fca-b5a4-28a4e30b49de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = {\"country\"  : [\"Brazil\", \"Russia\", \"India\", \"China\", \"South Africa\"],\n",
    "        \"capital\"   : [\"Brasilia\", \"Moscow\", \"New Dehli\", \"Beijing\", \"Pretoria\"],\n",
    "        \"area\"      : [8.516, 17.10, 3.286, 9.597],\n",
    "        \"population\": [200.4, 143.5, 1252, 1357, 52.98] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9df6591-785a-41a8-b61d-2d6eef854857",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(dict1, orient=\"index\")\n",
    "df = df.transpose()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c19053b-5624-4166-a163-33f0a98ced82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a72488-f565-461d-9198-4d64ccc012c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(df.shape[0]):\n",
    "    for value in df.keys():\n",
    "        print(df[value].iloc[row])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942d0c5f-186e-4bac-956d-d3311768ffe5",
   "metadata": {},
   "source": [
    "## Get Second Page from News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c6870f-bbd6-4ccc-9317-f5bdf14e0b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_and_second_news_page_also_photo_using_bs4(links, numbers):\n",
    "    news = []\n",
    "    for link in links:\n",
    "        response = requests.get(link).content\n",
    "        time.sleep(1)\n",
    "        soup = bs(response)\n",
    "        \n",
    "        if soup.find(attrs= {\"dtr-evt\": \"selanjutnya\"}).get_text(strip=True).lower() == 'selanjutnya':\n",
    "            # title\n",
    "            try:\n",
    "                news_title = soup.find(class_=\"detail__title\").get_text(strip=True)\n",
    "            except:\n",
    "                news_title = None\n",
    "                print(\"Error: No such news title element\")\n",
    "            # date\n",
    "            try:\n",
    "                news_date  = soup.find(class_=\"detail__date\").get_text()\n",
    "            except:\n",
    "                news_date = None\n",
    "                print(\"Error: No such news date element\")\n",
    "            # body\n",
    "            try:\n",
    "                news_raw   = soup.find(class_=\"detail__body-text itp_bodycontent\")\n",
    "                news_body_raw = [body.get_text() for body in news_raw.find_all(\"p\")]\n",
    "                news_body_head  = soup.strong.get_text()\n",
    "                news_body_bottom  = \"\\n\".join(news_body_raw)\n",
    "                news_body = news_body_head + \" - \" + news_body_bottom\n",
    "                try:\n",
    "                    news_body_add_1 = news_raw.find(\"h2\").get_text()\n",
    "                    news_body = news_body + \"\\n\" + news_body_add_1\n",
    "                    try:\n",
    "                        news_body_add_2 = [body.get_text() for body in news_raw.find(\"ul\")]\n",
    "                        news_body_add_2  = \"\\n\".join(news_body_add_2)\n",
    "                        news_body = news_body + \"\\n\" + news_body_add_2\n",
    "                    except:\n",
    "                        pass\n",
    "                except:\n",
    "                    pass\n",
    "            except:\n",
    "                news_body = None\n",
    "                print(\"Error: No such news body element\")\n",
    "            # body 2\n",
    "            try:\n",
    "                driver.switch_to.window(driver.window_handles[1])\n",
    "                driver.get(link)\n",
    "                time.sleep(1)\n",
    "\n",
    "                next_page = driver.find_element(By.CLASS_NAME, \"detail__long-nav\")\n",
    "                next_page.find_element(By.XPATH, \"//a[@dtr-evt='selanjutnya']\").click()\n",
    "                link_second = driver.current_url\n",
    "\n",
    "                response_second = requests.get(link_second).content\n",
    "                soup_second = bs(response_second)\n",
    "            except:\n",
    "                print(\"Error: Cannot move to second page\")\n",
    "\n",
    "            try:\n",
    "                news_raw   = soup_second.find(class_=\"detail__body-text itp_bodycontent\")\n",
    "                news_body_raw = [body.get_text() for body in news_raw.find_all(\"p\")]\n",
    "                news_body_second  = \"\\n\".join(news_body_raw)\n",
    "                news_body = news_body + \"\\n\" + \"Halaman 2\" +\"\\n\" + news_body_second\n",
    "            except:\n",
    "                print(\"Error: No such second news body element\")\n",
    "                \n",
    "            driver.switch_to.window(driver.window_handles[0])\n",
    "\n",
    "        else:\n",
    "            # title\n",
    "            try:\n",
    "                news_title = soup.find(class_=\"detail__title\").get_text(strip=True)\n",
    "            except:\n",
    "                print(\"Use second algorithm to get news title\")            \n",
    "                try:\n",
    "                    news_title = soup.h1.get_text()\n",
    "                except:\n",
    "                    news_title = None\n",
    "                    print(\"Error: No such news title element\")\n",
    "            # date\n",
    "            try:\n",
    "                news_date  = soup.find(class_=\"detail__date\").get_text()\n",
    "            except:\n",
    "                print(\"Use second algorithm to get news date\")            \n",
    "                try:\n",
    "                    news_date = soup.find(class_=\"date\").get_text()\n",
    "                except:\n",
    "                    news_date = None\n",
    "                    print(\"Error: No such news date element\")\n",
    "            # body\n",
    "            try:\n",
    "                news_raw   = soup.find(class_=\"detail__body-text itp_bodycontent\")\n",
    "                news_body_raw = [body.get_text() for body in news_raw.find_all(\"p\")]\n",
    "                news_body_head  = soup.strong.get_text()\n",
    "                news_body_bottom  = \"\\n\".join(news_body_raw)\n",
    "                news_body = news_body_head + \" - \" + news_body_bottom\n",
    "                try:\n",
    "                    news_body_add_1 = news_raw.find(\"h2\").get_text()\n",
    "                    news_body = news_body + \"\\n\" + news_body_add_1\n",
    "                    try:\n",
    "                        news_body_add_2 = [body.get_text() for body in news_raw.find(\"ul\")]\n",
    "                        news_body_add_2  = \"\\n\".join(news_body_add_2)\n",
    "                        news_body = news_body + \"\\n\" + news_body_add_2\n",
    "                    except:\n",
    "                        pass\n",
    "                except:\n",
    "                    pass\n",
    "                if news_body == \" - \":\n",
    "                    news_body = None\n",
    "                else:\n",
    "                    pass\n",
    "            except:\n",
    "                print(\"Use second algorithm to get news body\")  \n",
    "                try:\n",
    "                    news_raw = soup.find(class_=\"itp_bodycontent detail_text group\")\n",
    "                    news_body_raw = [body.get_text() for body in news_raw.find_all(\"p\")]\n",
    "                    news_body_head = soup.strong.get_text()\n",
    "                    news_body_bottom = \"\\n\".join(news_body_raw)\n",
    "                    news_body = news_body_head + \" - \" + news_body_bottom\n",
    "                except:\n",
    "                    print(\"Use third algorithm to get news body\")\n",
    "                    try:\n",
    "                        news_raw = soup.find(id=\"detikdetailtext\")\n",
    "                        news_body_raw = [body.get_text() for body in news_raw.find_all(\"p\")]\n",
    "                        try:\n",
    "                            news_body_head = news_raw.b.get_text()\n",
    "                        except:\n",
    "                            news_body_head = news_raw.strong.get_text()\n",
    "                        news_body_bottom = \"\\n\".join(news_body_raw)\n",
    "                        news_body = news_body_head + \" - \" + news_body_bottom\n",
    "                    except:\n",
    "                        print(\"Use Forth algorithm to get news body\")\n",
    "                        try:\n",
    "                            news_body_head = soup.find(\"p\").get_text()\n",
    "                            news_body_bottom = soup.find(\"figcaption\").get_text()\n",
    "                            news_body = news_body_head + \" \" +news_body_bottom\n",
    "                        except:\n",
    "                            print(\"Use Fifth algorithm to get news body\")\n",
    "                            try:\n",
    "                                news_body = soup.find(\"p\").get_text()\n",
    "                            except:\n",
    "                                news_body = None\n",
    "                                print(\"Error: No such news body element\")\n",
    "\n",
    "        news.append({\"judul\":news_title, \"tanggal\":news_date, \"isi\":news_body})\n",
    "        numbers += 1\n",
    "        print(f\"News: {numbers}\\n{news_title}\\n\")\n",
    "    return news, number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b6b3ee-ac2f-434f-a238-081847f5c920",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(news)\n",
    "print(df.isi.loc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7299c025-ecbc-4b54-bb9c-e167d7c04f31",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Trial and Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f49eed-10a0-48f9-a284-10e3a0f34632",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1bb1b1d-02c9-415d-b283-cc6452f3a8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def algorithm_news_title(soup):\n",
    "    try:\n",
    "        news_title = soup.find(class_=\"detail__title\").get_text(strip=True)\n",
    "    except:\n",
    "        try:\n",
    "            news_title = soup.h1.get_text()\n",
    "        except:\n",
    "            news_title = None\n",
    "            print(\"Error: No such news title element\")\n",
    "    return news_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61178d3a-c1dc-4756-a356-27063bb76b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def algorithm_news_date(soup):\n",
    "    try:\n",
    "        news_date  = soup.find(class_=\"detail__date\").get_text()\n",
    "    except:\n",
    "        try:\n",
    "            news_date = soup.find(class_=\"date\").get_text()\n",
    "        except:\n",
    "            news_date = None\n",
    "            print(\"Error: No such news date element\")\n",
    "    return news_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6331c975-6a3f-4df7-8f90-7dccbb5028b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_algorithm_news_body(soup):\n",
    "    news_raw   = soup.find(class_=\"detail__body-text itp_bodycontent\")\n",
    "    news_body_raw = [body.get_text() for body in news_raw.find_all(\"p\")]\n",
    "    news_body_head  = soup.strong.get_text()\n",
    "    news_body_bottom  = \"\\n\".join(news_body_raw)\n",
    "    news_body = news_body_head + \" - \" + news_body_bottom\n",
    "    # if theres some add in bottom\n",
    "    try:\n",
    "        news_body_add_1 = news_raw.find(\"h2\").get_text()\n",
    "        news_body = news_body + \"\\n\" + news_body_add_1\n",
    "        try:\n",
    "            news_body_add_2 = [body.get_text() for body in news_raw.find(\"ul\")]\n",
    "            news_body_add_2  = \"\\n\".join(news_body_add_2)\n",
    "            news_body = news_body + \"\\n\" + news_body_add_2\n",
    "        except:\n",
    "            pass\n",
    "    except:\n",
    "        pass\n",
    "    if news_body == \" - \":\n",
    "        news_body = None\n",
    "    else:\n",
    "        pass\n",
    "    return news_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47b01752-853d-4acc-950c-19d156597324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_algorithm_news_body(soup):\n",
    "    news_raw = soup.find(class_=\"itp_bodycontent detail_text group\")\n",
    "    news_body_raw = [body.get_text() for body in news_raw.find_all(\"p\")]\n",
    "    news_body_head = soup.strong.get_text()\n",
    "    news_body_bottom = \"\\n\".join(news_body_raw)\n",
    "    news_body = news_body_head + \" - \" + news_body_bottom\n",
    "    # if theres some add in bottom\n",
    "    try:\n",
    "        news_body_add_1 = news_raw.find(\"h2\").get_text()\n",
    "        news_body = news_body + \"\\n\" + news_body_add_1\n",
    "        try:\n",
    "            news_body_add_2 = [body.get_text() for body in news_raw.find(\"ul\")]\n",
    "            news_body_add_2  = \"\\n\".join(news_body_add_2)\n",
    "            news_body = news_body + \"\\n\" + news_body_add_2\n",
    "        except:\n",
    "            pass\n",
    "    except:\n",
    "        pass\n",
    "    if news_body == \" - \":\n",
    "        news_body = None\n",
    "    else:\n",
    "        pass\n",
    "    return news_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "05af77d0-7a0d-4f5e-b228-7b2c3012b3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def third_algorithm_news_body(soup):\n",
    "    news_raw = soup.find(id=\"detikdetailtext\")\n",
    "    news_body_raw = [body.get_text() for body in news_raw.find_all(\"p\")]\n",
    "    try:\n",
    "        news_body_head = news_raw.b.get_text()\n",
    "    except:\n",
    "        news_body_head = news_raw.strong.get_text()\n",
    "    news_body_bottom = \"\\n\".join(news_body_raw)\n",
    "    news_body = news_body_head + \" - \" + news_body_bottom\n",
    "    # if theres some add in bottom\n",
    "    try:\n",
    "        news_body_add_1 = news_raw.find(\"h2\").get_text()\n",
    "        news_body = news_body + \"\\n\" + news_body_add_1\n",
    "        try:\n",
    "            news_body_add_2 = [body.get_text() for body in news_raw.find(\"ul\")]\n",
    "            news_body_add_2  = \"\\n\".join(news_body_add_2)\n",
    "            news_body = news_body + \"\\n\" + news_body_add_2\n",
    "        except:\n",
    "            pass\n",
    "    except:\n",
    "        pass\n",
    "    if news_body == \" - \":\n",
    "        news_body = None\n",
    "    else:\n",
    "        pass\n",
    "    return news_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0df6139c-532c-410e-8084-3ada9bcc1db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forth_algorithm_news_body(soup):\n",
    "    news_body_head = soup.find(\"p\").get_text()\n",
    "    news_body_bottom = soup.find(\"figcaption\").get_text()\n",
    "    news_body = news_body_head + \" \" +news_body_bottom\n",
    "    return news_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6d63ebe-219c-48b5-90c5-b77f1d1e17fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fifth_algorithm_news_body(soup):\n",
    "    news_body = soup.find(\"p\").get_text()\n",
    "    return news_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87d9ee14-307b-4805-b7d4-5bcb50c22bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_algorithm_news_body_second(soup_second, news_body):\n",
    "    news_raw   = soup_second.find(class_=\"detail__body-text itp_bodycontent\")\n",
    "    news_body_raw = [body.get_text() for body in news_raw.find_all(\"p\")]\n",
    "    news_body_second  = \"\\n\".join(news_body_raw)\n",
    "    news_body = news_body + \"\\n\" + \"Halaman 2\" +\"\\n\" + news_body_second\n",
    "    return news_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ce2849a-c919-483e-8e3e-86f625454074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_algorithm_news_body_second(soup_second, news_body):\n",
    "    news_raw   = soup_second.find(id=\"detikdetailtext\")\n",
    "    news_body_raw = [body.get_text() for body in news_raw.find_all(\"p\")]\n",
    "    news_body_second  = \"\\n\".join(news_body_raw)\n",
    "    news_body = news_body + \"\\n\" + \"Halaman 2\" +\"\\n\" + news_body_second\n",
    "    return news_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e4a9920-73d4-467f-8c40-c6438108f36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link_use_selenium(driver):\n",
    "    \"\"\"\n",
    "    Will also get for photo news link\n",
    "    \"\"\"\n",
    "    try:\n",
    "        get_news = driver.find_element(By.CLASS_NAME, \"list.media_rows.list-berita\")\n",
    "        get_news = get_news.find_elements(By.TAG_NAME, \"article\")\n",
    "        links = []\n",
    "        for link in get_news:\n",
    "            link = link.find_element(By.TAG_NAME, \"a\")\n",
    "            links.append(link.get_attribute(\"href\"))\n",
    "    except:\n",
    "        print(\"Error: No Such Link Box Element\")\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff2e0713-fdd9-4edd-b21c-67ce0a70f71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link_use_bs4(link):\n",
    "    try:\n",
    "        response = requests.get(link).content\n",
    "        soup = bs(response)\n",
    "        news_body_list = soup.find(class_=\"list media_rows list-berita\")\n",
    "        links = []\n",
    "        for news_link in news_body_list.find_all(\"a\"):\n",
    "            links.append(news_link.get(\"href\"))\n",
    "    except:\n",
    "        print(\"Error: No Such Link Box Element\")\n",
    "        \n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44bcda8d-a746-43c2-8ced-09fe76241dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_use_bs(links, numbers):\n",
    "    news = []\n",
    "    for link in links:\n",
    "        response = requests.get(link).content\n",
    "        time.sleep(1)\n",
    "        soup = bs(response, \"html.parser\")\n",
    "        # for news more than one page\n",
    "        try:\n",
    "            lanjutan = soup.find(class_=\"btn btn--red-base btn--sm mgb-24\").get_text(strip=True)\n",
    "            print(f\"Berita ada {lanjutan}\")\n",
    "            news_title = algorithm_news_title(soup=soup)\n",
    "            news_date = algorithm_news_date(soup=soup)\n",
    "            # body 1\n",
    "            try:\n",
    "                news_body = first_algorithm_news_body(soup=soup)\n",
    "            except:\n",
    "                try:\n",
    "                    news_body = second_algorithm_news_body(soup=soup)\n",
    "                except:\n",
    "                    try:\n",
    "                        news_body = third_algorithm_news_body(soup=soup)\n",
    "                    except:\n",
    "                        news_body = None\n",
    "                        print(\"Error: No such news body element\")\n",
    "            # body 2\n",
    "            try:\n",
    "                link_second = soup.find(class_=\"btn btn--red-base btn--sm mgb-24\").get(\"href\")\n",
    "                response_second = requests.get(link_second).content\n",
    "                soup_second = bs(response_second, \"html.parser\")\n",
    "                try:\n",
    "                    news_body = first_algorithm_news_body_second(soup_second=soup_second, news_body=news_body)\n",
    "                except:\n",
    "                    print(\"Error: No such second news body element\")\n",
    "            except:\n",
    "                print(\"Error: Cannot get second page link\")\n",
    "                \n",
    "        except:\n",
    "            # algorithm 2 to get second news\n",
    "            try:\n",
    "                lanjutan = soup.find(class_=\"ap-view\").get_text()\n",
    "                print(f\"Berita ada {lanjutan}: Use Second Algorithm\")\n",
    "\n",
    "                news_title = algorithm_news_title(soup=soup)\n",
    "                news_date = algorithm_news_date(soup=soup)\n",
    "                # body 1\n",
    "                try:\n",
    "                    news_body = first_algorithm_news_body(soup=soup)\n",
    "                except:\n",
    "                    try:\n",
    "                        news_body = second_algorithm_news_body(soup=soup)\n",
    "                    except:\n",
    "                        try:\n",
    "                            news_body = third_algorithm_news_body(soup=soup)\n",
    "                        except:\n",
    "                            news_body = None\n",
    "                            print(\"Error: No such news body element\")\n",
    "                # body 2\n",
    "                try:\n",
    "                    link_second = soup.find(\"a\", class_=\"ap-view\").get(\"href\")\n",
    "                    response_second = requests.get(link_second).content\n",
    "                    soup_second = bs(response_second, \"html.parser\")\n",
    "                    try:\n",
    "                        news_body = second_algorithm_news_body_second(soup_second=soup_second, news_body=news_body)\n",
    "                    except:\n",
    "                        print(\"Error: No such second news body element\")\n",
    "                except:\n",
    "                    print(\"Error: Cannot get second page link\")\n",
    "\n",
    "            except:\n",
    "                # for news that just one page\n",
    "                news_title = algorithm_news_title(soup=soup)\n",
    "                news_date = algorithm_news_date(soup=soup)\n",
    "                try:\n",
    "                    news_body = first_algorithm_news_body(soup=soup)\n",
    "                except:\n",
    "                    try:\n",
    "                        news_body = second_algorithm_news_body(soup=soup)\n",
    "                    except:\n",
    "                        try:\n",
    "                            news_body = third_algorithm_news_body(soup=soup)\n",
    "                        except:\n",
    "                            news_body = None\n",
    "                            print(\"Error: No such news body element\")\n",
    "        news.append({\"judul\":news_title, \"tanggal\":news_date, \"isi\":news_body})\n",
    "        numbers += 1\n",
    "        print(f\"News: {numbers}\\n{news_title}\\n\")\n",
    "    return news, numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a380503-4cad-419c-8be4-74e33328dd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news_and_photo_using_bs(links, numbers):\n",
    "    news = []\n",
    "    for link in links:\n",
    "        response = requests.get(link).content\n",
    "        time.sleep(1)\n",
    "        soup = bs(response, \"html.parser\")\n",
    "        # for news more than one page\n",
    "        try:\n",
    "            lanjutan = soup.find(class_=\"btn btn--red-base btn--sm mgb-24\").get_text(strip=True)\n",
    "            print(f\"Berita ada {lanjutan}\")\n",
    "            news_title = algorithm_news_title(soup=soup)\n",
    "            news_date = algorithm_news_date(soup=soup)\n",
    "            # body 1\n",
    "            try:\n",
    "                news_body = first_algorithm_news_body(soup=soup)\n",
    "            except:\n",
    "                try:\n",
    "                    news_body = second_algorithm_news_body(soup=soup)\n",
    "                except:\n",
    "                    try:\n",
    "                        news_body = third_algorithm_news_body(soup=soup)\n",
    "                    except:\n",
    "                        news_body = None\n",
    "                        print(\"Error: No such news body element\")\n",
    "            # body 2\n",
    "            try:\n",
    "                link_second = soup.find(class_=\"btn btn--red-base btn--sm mgb-24\").get(\"href\")\n",
    "                response_second = requests.get(link_second).content\n",
    "                soup_second = bs(response_second, \"html.parser\")\n",
    "                try:\n",
    "                    news_body = first_algorithm_news_body_second(soup_second=soup_second, news_body=news_body)\n",
    "                except:\n",
    "                    print(\"Error: No such second news body element\")\n",
    "            except:\n",
    "                print(\"Error: Cannot get second page link\")\n",
    "            \n",
    "        except:\n",
    "            # algorithm 2 to get second news\n",
    "            try:\n",
    "                lanjutan = soup.find(class_=\"ap-view\").get_text()\n",
    "                print(f\"Berita ada {lanjutan}: Use Second Algorithm\")\n",
    "\n",
    "                news_title = algorithm_news_title(soup=soup)\n",
    "                news_date = algorithm_news_date(soup=soup)\n",
    "                # body 1\n",
    "                try:\n",
    "                    news_body = first_algorithm_news_body(soup=soup)\n",
    "                except:\n",
    "                    try:\n",
    "                        news_body = second_algorithm_news_body(soup=soup)\n",
    "                    except:\n",
    "                        try:\n",
    "                            news_body = third_algorithm_news_body(soup=soup)\n",
    "                        except:\n",
    "                            news_body = None\n",
    "                            print(\"Error: No such news body element\")\n",
    "                # body 2\n",
    "                try:\n",
    "                    link_second = soup.find(\"a\", class_=\"ap-view\").get(\"href\")\n",
    "                    response_second = requests.get(link_second).content\n",
    "                    soup_second = bs(response_second, \"html.parser\")\n",
    "                    try:\n",
    "                        news_body = second_algorithm_news_body_second(soup_second=soup_second, news_body=news_body)\n",
    "                    except:\n",
    "                        print(\"Error: No such second news body element\")\n",
    "                except:\n",
    "                    print(\"Error: Cannot get second page link\")\n",
    "            \n",
    "            except:\n",
    "                # for news that just one page\n",
    "                news_title = algorithm_news_title(soup=soup)\n",
    "                news_date = algorithm_news_date(soup=soup)\n",
    "                try:\n",
    "                    news_body = first_algorithm_news_body(soup=soup)\n",
    "                except:\n",
    "                    try:\n",
    "                        news_body = second_algorithm_news_body(soup=soup)\n",
    "                    except:\n",
    "                        try:\n",
    "                            news_body = third_algorithm_news_body(soup=soup)\n",
    "                        except:\n",
    "                            try:\n",
    "                                news_body = forth_algorithm_news_body(soup=soup)\n",
    "                            except:\n",
    "                                try:\n",
    "                                    news_body = fifth_algorithm_news_body(soup=soup)\n",
    "                                except:\n",
    "                                    news_body = None\n",
    "                                    print(\"Error: No such news body element\")\n",
    "\n",
    "        news.append({\"judul\":news_title, \"tanggal\":news_date, \"isi\":news_body})\n",
    "        numbers += 1\n",
    "        print(f\"News: {numbers}\\n{news_title}\\n\")\n",
    "    return news, numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50e960a-6ddc-4e38-8a24-cedabce30683",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Use Keyword"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbaeb82-2529-4940-afe3-e99fe037054a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Exclude Photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2e8071-1281-4eb9-a27f-1cf7be4e6b1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def news_use_keyword():\n",
    "    keyword = input(\"Looking For? \")\n",
    "    end_page = int(input(\"Search Until Page: \"))\n",
    "    number = 0\n",
    "    all_news = []\n",
    "\n",
    "    driver = webdriver.Edge()\n",
    "    driver.get(\"https://www.detik.com\")\n",
    "\n",
    "    search_box = driver.find_element(By.NAME, \"query\")\n",
    "    search_box.send_keys(keyword)\n",
    "    search_box.send_keys(Keys.RETURN)\n",
    "\n",
    "    time.sleep(1)\n",
    "    links = get_link_use_selenium(driver=driver)\n",
    "    news, number = get_news_use_bs(links=links, numbers=number)\n",
    "    all_news.extend(news)\n",
    "\n",
    "    if end_page > 1:\n",
    "        for page in range(2, end_page+1):\n",
    "            driver.find_element(By.LINK_TEXT, str(page)).click()\n",
    "            time.sleep(1)\n",
    "            links = get_link_use_selenium(driver=driver)\n",
    "            news, number = get_news_use_bs(links=links, numbers=number)\n",
    "            all_news.extend(news)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    print(\"Done\")\n",
    "    driver.quit()\n",
    "\n",
    "    return all_news"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1e96a7-3e40-484b-a5d5-d58ccae0365c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Include Photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa6e89b-2067-48c4-9c0c-2b36435a5987",
   "metadata": {},
   "outputs": [],
   "source": [
    "def news_use_keyword_include_photo():\n",
    "    keyword = input(\"Looking For? \")\n",
    "    end_page = int(input(\"Search Until Page: \"))\n",
    "    number = 0\n",
    "    all_news = []\n",
    "\n",
    "    driver = webdriver.Edge()\n",
    "    driver.get(\"https://www.detik.com\")\n",
    "\n",
    "    search_box = driver.find_element(By.NAME, \"query\")\n",
    "    search_box.send_keys(keyword)\n",
    "    search_box.send_keys(Keys.RETURN)\n",
    "\n",
    "    time.sleep(1)\n",
    "    links = get_link_use_selenium(driver=driver)\n",
    "    news, number = get_news_and_photo_using_bs(links=links, numbers=number)\n",
    "    all_news.extend(news)\n",
    "\n",
    "    if end_page > 1:\n",
    "        for page in range(2, end_page+1):\n",
    "            driver.find_element(By.LINK_TEXT, str(page)).click()\n",
    "            time.sleep(1)\n",
    "            links = get_link_use_selenium(driver=driver)\n",
    "            news, number = get_news_and_photo_using_bs(links=links, numbers=number)\n",
    "            all_news.extend(news)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    print(\"Done\")\n",
    "    driver.quit()\n",
    "    return all_news"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc6d90f-2852-453b-9bd6-645b79bfd330",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Use Tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a058ffff-53d4-47c3-86ae-2d0c4d7f6b6c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Exclude Photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cb111815-7854-4d1f-b79f-20f770f5307c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def news_use_tag():\n",
    "    tag_name = input(\"Insert Tag: \")\n",
    "    end_page = int(input(\"Search Until Page: \"))\n",
    "    numbers = 0\n",
    "    all_news = []\n",
    "    link = \"https://www.detik.com/tag/\" + tag_name.replace(\" \", \"-\")\n",
    "\n",
    "    driver = webdriver.Edge()\n",
    "    driver.get(link)\n",
    "\n",
    "    time.sleep(1)\n",
    "    links = get_link_use_selenium(driver=driver)\n",
    "    news, numbers = get_news_use_bs(links=links, numbers=numbers)\n",
    "    all_news.extend(news)\n",
    "\n",
    "    if end_page > 1:\n",
    "        for page in range(2, end_page+1):\n",
    "            driver.find_element(By.LINK_TEXT, str(page)).click()\n",
    "            time.sleep(1)\n",
    "            links = get_link_use_selenium(driver=driver)\n",
    "            news, numbers = get_news_use_bs(links=links, numbers=numbers)\n",
    "            all_news.extend(news)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    print(\"Done\")\n",
    "    driver.quit()\n",
    "    return all_news"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec5aa06-ac5c-4ab2-8ffa-a50a9623252b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Include Photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f9e167a-aa92-4129-935a-ed38cf48315d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def news_use_tag_include_photo():\n",
    "    tag_name = input(\"Insert Tag: \")\n",
    "    end_page = int(input(\"Search Until Page: \"))\n",
    "    numbers = 0\n",
    "    all_news = []\n",
    "    link = \"https://www.detik.com/tag/\" + tag_name.replace(\" \", \"-\")\n",
    "\n",
    "    driver = webdriver.Edge()\n",
    "    driver.get(link)\n",
    "\n",
    "    time.sleep(1)\n",
    "    links = get_link_use_selenium(driver=driver)\n",
    "    news, numbers = get_news_and_photo_using_bs(links=links, numbers=numbers)\n",
    "    all_news.extend(news)\n",
    "\n",
    "    if end_page > 1:\n",
    "        for page in range(2, end_page+1):\n",
    "            driver.find_element(By.LINK_TEXT, str(page)).click()\n",
    "            time.sleep(1)\n",
    "            links = get_link_use_selenium(driver=driver)\n",
    "            news, numbers = get_news_and_photo_using_bs(links=links, numbers=numbers)\n",
    "            all_news.extend(news)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    print(\"Done\")\n",
    "    driver.quit()\n",
    "    return all_news"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb346283-2a82-4f51-89c3-b01b40252d1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "259d86cf-2bfa-4d54-b718-040b1c53781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detik_scraping import news_use_keyword, news_use_tag, using_certain_page\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4587e6d8-025d-4d9e-b6a9-4fc288978574",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "news = news_use_keyword()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2df37a7-6c9d-43e2-bbb7-e8ded1c0a93e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "news = news_use_tag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd80728-c3ed-4788-b1d7-20f612fd9079",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "news = using_certain_page()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249999d8-c83d-499d-8d6e-7fcf4d27e973",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save to Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96d6123e-ff0a-4ce4-80bb-f6f3c089785b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13a8dcb6-ba8c-46d7-86e5-bc81cb865f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using non photo\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93716f8c-1981-43ce-9328-c0a07d5e6b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "df.to_csv(\"berita.csv\", sep=\";\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1ee07b8a-5d56-4c8c-b69b-364c73e7ee78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv\n",
    "df = pd.read_csv(\"berita.csv\", delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "236d659a-fff3-46ae-8a84-54350c00aabf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judul</th>\n",
       "      <th>tanggal</th>\n",
       "      <th>isi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Demo 11 April di Pati Diwarnai Saling Dorong d...</td>\n",
       "      <td>Senin, 11 Apr 2022 11:57 WIB</td>\n",
       "      <td>Pati - Sejumlah mahasiswa menggelar aksi demo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arti Inflasi: Penyebab, Jenis, Dampak, Contoh ...</td>\n",
       "      <td>Senin, 11 Apr 2022 10:56 WIB</td>\n",
       "      <td>Jakarta - Inflasi adalah kenaikan harga secara...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Urgensi Sanksi Hukum untuk Para Mafia Kebutuha...</td>\n",
       "      <td>Senin, 11 Apr 2022 09:46 WIB</td>\n",
       "      <td>Jakarta - Kasus Spekulasi Mafia Kebutuhan Poko...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Catat! Ini Daftar BBM yang Harganya Naik</td>\n",
       "      <td>8 Views  |  Rabu, 10 Okt 2018 15:25 WIB</td>\n",
       "      <td>Sejumlah harga bahan bakar minyak (BBM) mengal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harga Pangan Hingga BBM Naik Bikin Negara Ini ...</td>\n",
       "      <td>Senin, 11 Apr 2022 08:37 WIB</td>\n",
       "      <td>Jakarta - Harga pangan global telah mengalami ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Antrean Solar Hilang, Warga Sumbar Berterima K...</td>\n",
       "      <td>Senin, 11 Apr 2022 07:01 WIB</td>\n",
       "      <td>Jakarta - Kelangkaan solar atau biosolar bersu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ekonomi Belum Stabil, Harga Pertalite dan LPG ...</td>\n",
       "      <td>Senin, 11 Apr 2022 04:00 WIB</td>\n",
       "      <td>Jakarta - Pemerintah membuka opsi untuk menaik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Awas! Wacana Kenaikan Harga Bisa Bikin Elpiji ...</td>\n",
       "      <td>Minggu, 10 Apr 2022 21:45 WIB</td>\n",
       "      <td>Jakarta - Wacana kenaikan Elpiji 3 kilogram da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Harga Pertalite &amp; Elpiji 3 Kg Tak Perlu Naik, ...</td>\n",
       "      <td>Minggu, 10 Apr 2022 18:00 WIB</td>\n",
       "      <td>Jakarta - BBM jenis Pertalite dan Elpiji 3 kil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Muncul Seruan Aksi Tolak Kenaikan BBM-PPN di S...</td>\n",
       "      <td>Minggu, 10 Apr 2022 16:38 WIB</td>\n",
       "      <td>Sukabumi - Media perpesanan diramaikan dengan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>YLBHI dkk Tolak Jokowi 3 Periode: Sudah Jadi G...</td>\n",
       "      <td>Minggu, 10 Apr 2022 14:47 WIB</td>\n",
       "      <td>Jakarta - Yayasan Lembaga Bantuan Hukum Indone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Harga Pertalite dan LPG 3 Kg Jangan Naik Dulu,...</td>\n",
       "      <td>Minggu, 10 Apr 2022 14:31 WIB</td>\n",
       "      <td>Jakarta - Pemerintah membuka opsi untuk menaik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Setelah Luhut, Giliran Menteri ESDM Beri Sinya...</td>\n",
       "      <td>Sabtu, 09 Apr 2022 18:48 WIB</td>\n",
       "      <td>Jakarta - Menteri Energi dan Sumber Daya Miner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Harga BBM Naik, Masyarakat Bakar Mobil</td>\n",
       "      <td>75 Views  |  Minggu, 08 Jul 2018 10:01 WIB</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Menteri ESDM: Harga Minyak Naik US$ 1, Beban S...</td>\n",
       "      <td>Sabtu, 09 Apr 2022 18:30 WIB</td>\n",
       "      <td>Jakarta - Menteri Energi dan Sumber Daya Miner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Menteri ESDM Beri Sinyal Harga LPG 3 Kg Segera...</td>\n",
       "      <td>Sabtu, 09 Apr 2022 18:09 WIB</td>\n",
       "      <td>Medan - \"Betul,\" kata Arifin saat ditanyai soa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Menteri ESDM: Minyak Dunia Naik 1 Dolar, Butuh...</td>\n",
       "      <td>Sabtu, 09 Apr 2022 16:28 WIB</td>\n",
       "      <td>Medan - Jika harga minyak dunia naik US$ 1, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Petani Lamongan Sambat Solar Langka-Gabah Mura...</td>\n",
       "      <td>Sabtu, 09 Apr 2022 14:46 WIB</td>\n",
       "      <td>Lamongan - Menteri BUMN Erick Thohir melakukan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Tolak Presiden 3 Periode, Mahasiswa Surabaya S...</td>\n",
       "      <td>Sabtu, 09 Apr 2022 13:30 WIB</td>\n",
       "      <td>Surabaya - Sejumlah elemen mahasiswa dari seju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Tak Cuma RI, Ini Daftar Negara yang Naikkan Ha...</td>\n",
       "      <td>Jumat, 08 Apr 2022 20:15 WIB</td>\n",
       "      <td>Jakarta - Harga minyak dunia meroket tajam aki...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                judul  \\\n",
       "0   Demo 11 April di Pati Diwarnai Saling Dorong d...   \n",
       "1   Arti Inflasi: Penyebab, Jenis, Dampak, Contoh ...   \n",
       "2   Urgensi Sanksi Hukum untuk Para Mafia Kebutuha...   \n",
       "3            Catat! Ini Daftar BBM yang Harganya Naik   \n",
       "4   Harga Pangan Hingga BBM Naik Bikin Negara Ini ...   \n",
       "5   Antrean Solar Hilang, Warga Sumbar Berterima K...   \n",
       "6   Ekonomi Belum Stabil, Harga Pertalite dan LPG ...   \n",
       "7   Awas! Wacana Kenaikan Harga Bisa Bikin Elpiji ...   \n",
       "8   Harga Pertalite & Elpiji 3 Kg Tak Perlu Naik, ...   \n",
       "9   Muncul Seruan Aksi Tolak Kenaikan BBM-PPN di S...   \n",
       "10  YLBHI dkk Tolak Jokowi 3 Periode: Sudah Jadi G...   \n",
       "11  Harga Pertalite dan LPG 3 Kg Jangan Naik Dulu,...   \n",
       "12  Setelah Luhut, Giliran Menteri ESDM Beri Sinya...   \n",
       "13             Harga BBM Naik, Masyarakat Bakar Mobil   \n",
       "14  Menteri ESDM: Harga Minyak Naik US$ 1, Beban S...   \n",
       "15  Menteri ESDM Beri Sinyal Harga LPG 3 Kg Segera...   \n",
       "16  Menteri ESDM: Minyak Dunia Naik 1 Dolar, Butuh...   \n",
       "17  Petani Lamongan Sambat Solar Langka-Gabah Mura...   \n",
       "18  Tolak Presiden 3 Periode, Mahasiswa Surabaya S...   \n",
       "19  Tak Cuma RI, Ini Daftar Negara yang Naikkan Ha...   \n",
       "\n",
       "                                       tanggal  \\\n",
       "0                 Senin, 11 Apr 2022 11:57 WIB   \n",
       "1                 Senin, 11 Apr 2022 10:56 WIB   \n",
       "2                 Senin, 11 Apr 2022 09:46 WIB   \n",
       "3      8 Views  |  Rabu, 10 Okt 2018 15:25 WIB   \n",
       "4                 Senin, 11 Apr 2022 08:37 WIB   \n",
       "5                 Senin, 11 Apr 2022 07:01 WIB   \n",
       "6                 Senin, 11 Apr 2022 04:00 WIB   \n",
       "7                Minggu, 10 Apr 2022 21:45 WIB   \n",
       "8                Minggu, 10 Apr 2022 18:00 WIB   \n",
       "9                Minggu, 10 Apr 2022 16:38 WIB   \n",
       "10               Minggu, 10 Apr 2022 14:47 WIB   \n",
       "11               Minggu, 10 Apr 2022 14:31 WIB   \n",
       "12                Sabtu, 09 Apr 2022 18:48 WIB   \n",
       "13  75 Views  |  Minggu, 08 Jul 2018 10:01 WIB   \n",
       "14                Sabtu, 09 Apr 2022 18:30 WIB   \n",
       "15                Sabtu, 09 Apr 2022 18:09 WIB   \n",
       "16                Sabtu, 09 Apr 2022 16:28 WIB   \n",
       "17                Sabtu, 09 Apr 2022 14:46 WIB   \n",
       "18                Sabtu, 09 Apr 2022 13:30 WIB   \n",
       "19                Jumat, 08 Apr 2022 20:15 WIB   \n",
       "\n",
       "                                                  isi  \n",
       "0   Pati - Sejumlah mahasiswa menggelar aksi demo ...  \n",
       "1   Jakarta - Inflasi adalah kenaikan harga secara...  \n",
       "2   Jakarta - Kasus Spekulasi Mafia Kebutuhan Poko...  \n",
       "3   Sejumlah harga bahan bakar minyak (BBM) mengal...  \n",
       "4   Jakarta - Harga pangan global telah mengalami ...  \n",
       "5   Jakarta - Kelangkaan solar atau biosolar bersu...  \n",
       "6   Jakarta - Pemerintah membuka opsi untuk menaik...  \n",
       "7   Jakarta - Wacana kenaikan Elpiji 3 kilogram da...  \n",
       "8   Jakarta - BBM jenis Pertalite dan Elpiji 3 kil...  \n",
       "9   Sukabumi - Media perpesanan diramaikan dengan ...  \n",
       "10  Jakarta - Yayasan Lembaga Bantuan Hukum Indone...  \n",
       "11  Jakarta - Pemerintah membuka opsi untuk menaik...  \n",
       "12  Jakarta - Menteri Energi dan Sumber Daya Miner...  \n",
       "13                                               None  \n",
       "14  Jakarta - Menteri Energi dan Sumber Daya Miner...  \n",
       "15  Medan - \"Betul,\" kata Arifin saat ditanyai soa...  \n",
       "16  Medan - Jika harga minyak dunia naik US$ 1, ma...  \n",
       "17  Lamongan - Menteri BUMN Erick Thohir melakukan...  \n",
       "18  Surabaya - Sejumlah elemen mahasiswa dari seju...  \n",
       "19  Jakarta - Harga minyak dunia meroket tajam aki...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5ebe6d-a48b-4749-80e1-a1908ec45ec0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df.isi.loc[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3147e7-e875-4f6e-93dd-95793947e7cb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"berita.txt\", \"w\", encoding=\"utf-8\") as beritacuy:\n",
    "    number = 134\n",
    "    for row in range(df.shape[0]):\n",
    "        number += 1\n",
    "        print(f\"Berita ke {number}\")\n",
    "        beritacuy.write(f\"Berita ke {number}\\n\")\n",
    "        beritacuy.write(df.judul.iloc[row]+\"\\n\")\n",
    "        print(df.judul.iloc[row])\n",
    "        beritacuy.write(df.isi.iloc[row]+\"\\n\")\n",
    "        print(df.isi.iloc[row])\n",
    "        beritacuy.write(\"\\n\")\n",
    "        print()\n",
    "        time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096817a3-b800-40b1-89c7-d0e8ed901aec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "87ff449350a33bc28f3d8884670e38ac46fb80a68855065b54dc3dc8bb3e7896"
  },
  "kernelspec": {
   "display_name": "Python [conda env:datacollect]",
   "language": "python",
   "name": "conda-env-datacollect-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
